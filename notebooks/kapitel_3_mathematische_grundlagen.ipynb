{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Kapitel 3: Mathematische Grundlagen\n",
        "## Gradientenberechnung, Matrizenrechnung und Wahrscheinlichkeitsrechnung"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Gradientenberechnung"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Der Gradient ist ein Vektor, der die Richtung und Stärke der steilsten Steigung einer Funktion angibt.\n",
        "\n",
        "Für eine Funktion $f(x_1, x_2, ..., x_n)$ ist der Gradient:\n",
        "\n",
        "$$\\nabla f = \\begin{pmatrix} \\frac{\\partial f}{\\partial x_1} \\\\ \\frac{\\partial f}{\\partial x_2} \\\\ \\vdots \\\\ \\frac{\\partial f}{\\partial x_n} \\end{pmatrix}$$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import sympy as sp\n",
        "\n",
        "# Beispiel 1: Numerische Gradientenberechnung\n",
        "print(\"=== Beispiel 1: Numerische Gradientenberechnung ===\")\n",
        "\n",
        "def f(x):\n",
        "    \"\"\"Einfache quadratische Funktion: f(x1, x2) = x1^2 + 2*x2^2\"\"\"\n",
        "    return x[0]**2 + 2*x[1]**2\n",
        "\n",
        "def numerical_gradient(f, x, h=1e-5):\n",
        "    \"\"\"Berechnet den Gradienten numerisch (Vorwärtsdifferenz).\"\"\"\n",
        "    gradient = np.zeros_like(x, dtype=float)\n",
        "    fx = f(x)\n",
        "    for i in range(len(x)):\n",
        "        x_h = x.copy()\n",
        "        x_h[i] += h\n",
        "        gradient[i] = (f(x_h) - fx) / h\n",
        "    return gradient\n",
        "\n",
        "# Punkt, an dem wir den Gradienten berechnen\n",
        "x = np.array([3.0, 2.0])\n",
        "grad = numerical_gradient(f, x)\n",
        "\n",
        "print(f\"Punkt: {x}\")\n",
        "print(f\"Funktionswert f(x): {f(x):.4f}\")\n",
        "print(f\"Gradient ∇f(x): {grad}\")\n",
        "print(f\"Magnitude des Gradienten: {np.linalg.norm(grad):.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Beispiel 2: Analytische Gradientenberechnung mit SymPy\n",
        "print(\"\\n=== Beispiel 2: Analytische Gradientenberechnung ===\")\n",
        "\n",
        "x1, x2 = sp.symbols('x1 x2')\n",
        "f_sym = x1**2 + 2*x2**2\n",
        "\n",
        "# Partielle Ableitungen berechnen\n",
        "df_dx1 = sp.diff(f_sym, x1)\n",
        "df_dx2 = sp.diff(f_sym, x2)\n",
        "\n",
        "print(f\"f(x1, x2) = {f_sym}\")\n",
        "print(f\"∂f/∂x1 = {df_dx1}\")\n",
        "print(f\"∂f/∂x2 = {df_dx2}\")\n",
        "\n",
        "# Gradient an bestimmtem Punkt auswerten\n",
        "grad_x1 = df_dx1.subs({x1: 3, x2: 2})\n",
        "grad_x2 = df_dx2.subs({x1: 3, x2: 2})\n",
        "\n",
        "print(f\"\\n∇f(3, 2) = [{grad_x1}, {grad_x2}]\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Beispiel 3: Visualisierung des Gradienten\n",
        "print(\"\\n=== Beispiel 3: Visualisierung des Gradienten ===\")\n",
        "\n",
        "# Erzeuge ein Gitter\n",
        "x1_vals = np.linspace(-5, 5, 100)\n",
        "x2_vals = np.linspace(-5, 5, 100)\n",
        "X1, X2 = np.meshgrid(x1_vals, x2_vals)\n",
        "Z = X1**2 + 2*X2**2\n",
        "\n",
        "# Gradient an jedem Punkt\n",
        "dZ_dx1 = 2*X1\n",
        "dZ_dx2 = 4*X2\n",
        "\n",
        "fig = plt.figure(figsize=(14, 5))\n",
        "\n",
        "# Konturplot mit Gradient\n",
        "ax1 = fig.add_subplot(1, 2, 1)\n",
        "contour = ax1.contour(X1, X2, Z, levels=15, cmap='viridis')\n",
        "ax1.clabel(contour, inline=True, fontsize=8)\n",
        "ax1.quiver(\n",
        "    X1[::5, ::5], X2[::5, ::5],\n",
        "    dZ_dx1[::5, ::5], dZ_dx2[::5, ::5],\n",
        "    alpha=0.6\n",
        ")\n",
        "ax1.plot(0, 0, 'r*', markersize=15, label='Minimum')\n",
        "ax1.set_xlabel('x1')\n",
        "ax1.set_ylabel('x2')\n",
        "ax1.set_title('Konturplot mit Gradient-Vektoren')\n",
        "ax1.legend()\n",
        "ax1.grid(True, alpha=0.3)\n",
        "\n",
        "# 3D Oberflächenplot\n",
        "ax2 = fig.add_subplot(1, 2, 2, projection='3d')\n",
        "ax2.plot_surface(X1, X2, Z, cmap='viridis', alpha=0.7)\n",
        "ax2.set_xlabel('x1')\n",
        "ax2.set_ylabel('x2')\n",
        "ax2.set_zlabel('f(x1, x2)')\n",
        "ax2.set_title('3D Oberflächenplot')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"Gradient zeigt in Richtung des steilsten Anstiegs\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Beispiel 4: Gradient Descent (Gradientenabstieg)\n",
        "print(\"\\n=== Beispiel 4: Gradient Descent Optimierung ===\")\n",
        "\n",
        "def gradient_descent(starting_point, learning_rate=0.01, iterations=100):\n",
        "    \"\"\"Führt Gradientenabstieg durch.\"\"\"\n",
        "    x = starting_point.copy()\n",
        "    history = [x.copy()]\n",
        "\n",
        "    for _ in range(iterations):\n",
        "        grad = numerical_gradient(f, x)\n",
        "        x = x - learning_rate * grad\n",
        "        history.append(x.copy())\n",
        "\n",
        "    return x, np.array(history)\n",
        "\n",
        "# Gradient Descent starten\n",
        "start = np.array([4.0, 3.0])\n",
        "optimal, history = gradient_descent(start, learning_rate=0.05, iterations=100)\n",
        "\n",
        "print(f\"Startpunkt: {start}\")\n",
        "print(f\"Optimaler Punkt: {optimal}\")\n",
        "print(f\"Funktionswert am Optimum: {f(optimal):.6f}\")\n",
        "\n",
        "# Visualisierung des Optimierungspfads\n",
        "plt.figure(figsize=(10, 8))\n",
        "contour = plt.contour(X1, X2, Z, levels=20, cmap='viridis')\n",
        "plt.clabel(contour, inline=True, fontsize=8)\n",
        "plt.plot(history[:, 0], history[:, 1], 'ro-', alpha=0.5, markersize=4, label='Gradient Descent Pfad')\n",
        "plt.plot(history[0, 0], history[0, 1], 'gs', markersize=10, label='Startpunkt')\n",
        "plt.plot(history[-1, 0], history[-1, 1], 'r*', markersize=15, label='Minimum')\n",
        "plt.xlabel('x1')\n",
        "plt.ylabel('x2')\n",
        "plt.title('Gradient Descent Optimierungspfad')\n",
        "plt.legend()\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.colorbar(contour)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Matrizenrechnung"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Matrizen sind rechteckige Anordnungen von Zahlen. Grundlegende Operationen sind:\n",
        "- **Addition und Subtraktion**: elementweise\n",
        "- **Multiplikation**: Skalar-Multiplikation oder Matrix-Multiplikation\n",
        "- **Transponieren**: Zeilen und Spalten vertauschen\n",
        "- **Determinante und Inverse**: für quadratische Matrizen"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"=== Beispiel 1: Grundlegende Matrizenoperationen ===\")\n",
        "\n",
        "# Matrizen definieren\n",
        "A = np.array([\n",
        "    [1, 2, 3],\n",
        "    [4, 5, 6]\n",
        "])\n",
        "\n",
        "B = np.array([\n",
        "    [7, 8, 9],\n",
        "    [10, 11, 12]\n",
        "])\n",
        "\n",
        "print(f\"Matrix A:\\n{A}\")\n",
        "print(f\"\\nMatrix B:\\n{B}\")\n",
        "\n",
        "# Addition\n",
        "print(f\"\\nA + B:\\n{A + B}\")\n",
        "\n",
        "# Subtraktion\n",
        "print(f\"\\nA - B:\\n{A - B}\")\n",
        "\n",
        "# Skalar-Multiplikation\n",
        "print(f\"\\n2 * A:\\n{2 * A}\")\n",
        "\n",
        "# Transponieren\n",
        "print(f\"\\nA^T (Transponierte von A):\\n{A.T}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"\\n=== Beispiel 2: Matrix-Multiplikation ===\")\n",
        "\n",
        "# Matrix-Multiplikation A @ B ist nur möglich, wenn Spalten(A) = Zeilen(B)\n",
        "C = np.array([\n",
        "    [1, 2],\n",
        "    [3, 4],\n",
        "    [5, 6]\n",
        "])\n",
        "\n",
        "D = np.array([\n",
        "    [7, 8, 9],\n",
        "    [10, 11, 12]\n",
        "])\n",
        "\n",
        "print(f\"Matrix C (3x2):\\n{C}\")\n",
        "print(f\"\\nMatrix D (2x3):\\n{D}\")\n",
        "\n",
        "result = C @ D\n",
        "print(f\"\\nC @ D (3x3):\\n{result}\")\n",
        "print(f\"Shape: {result.shape}\")\n",
        "\n",
        "# Element-weise Multiplikation (Hadamard-Produkt)\n",
        "E = np.array([\n",
        "    [1, 2],\n",
        "    [3, 4]\n",
        "])\n",
        "\n",
        "F = np.array([\n",
        "    [5, 6],\n",
        "    [7, 8]\n",
        "])\n",
        "\n",
        "print(\"\\nElement-weise Multiplikation (Hadamard-Produkt):\")\n",
        "print(f\"E * F =\\n{E * F}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"\\n=== Beispiel 3: Determinante und Inverse ===\")\n",
        "\n",
        "G = np.array([\n",
        "    [1, 2],\n",
        "    [3, 4]\n",
        "])\n",
        "\n",
        "print(f\"Matrix G:\\n{G}\")\n",
        "\n",
        "det = np.linalg.det(G)\n",
        "print(f\"\\nDeterminante von G: {det:.4f}\")\n",
        "\n",
        "if det != 0:\n",
        "    G_inv = np.linalg.inv(G)\n",
        "    print(f\"\\nInverse von G:\\n{G_inv}\")\n",
        "\n",
        "    identity = G @ G_inv\n",
        "    print(f\"\\nVerifizierung: G @ G^-1 =\\n{identity}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"\\n=== Beispiel 4: Eigenwerte und Eigenvektoren ===\")\n",
        "\n",
        "H = np.array([\n",
        "    [4, -2],\n",
        "    [-2, 4]\n",
        "])\n",
        "\n",
        "print(f\"Matrix H:\\n{H}\")\n",
        "\n",
        "eigenvalues, eigenvectors = np.linalg.eig(H)\n",
        "\n",
        "print(f\"\\nEigenwerte: {eigenvalues}\")\n",
        "print(f\"\\nEigenvektoren:\\n{eigenvectors}\")\n",
        "\n",
        "for i in range(len(eigenvalues)):\n",
        "    v = eigenvectors[:, i]\n",
        "    lambda_i = eigenvalues[i]\n",
        "    result1 = H @ v\n",
        "    result2 = lambda_i * v\n",
        "    print(f\"\\nEigenwert {i+1}: λ = {lambda_i:.4f}\")\n",
        "    print(f\"H @ v = {result1}\")\n",
        "    print(f\"λ * v = {result2}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"\\n=== Beispiel 5: Lineare Gleichungssysteme ===\")\n",
        "\n",
        "# Löse: A @ x = b\n",
        "A = np.array([\n",
        "    [2, 1],\n",
        "    [1, 3]\n",
        "])\n",
        "\n",
        "b = np.array([5, 6])\n",
        "\n",
        "print(f\"Matrix A:\\n{A}\")\n",
        "print(f\"Vektor b: {b}\")\n",
        "print(\"\\nLöse: A @ x = b\")\n",
        "\n",
        "x = np.linalg.solve(A, b)\n",
        "print(f\"Lösung x: {x}\")\n",
        "\n",
        "check = A @ x\n",
        "print(f\"\\nVerifizierung: A @ x = {check}\")\n",
        "print(f\"Sollte gleich b = {b} sein\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Wahrscheinlichkeitsrechnung"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Wahrscheinlichkeitsrechnung befasst sich mit Zufallsereignissen und deren Wahrscheinlichkeiten.\n",
        "\n",
        "**Grundlegende Konzepte:**\n",
        "- **Wahrscheinlichkeit**: $P(A) \\in [0, 1]$\n",
        "- **Bedingte Wahrscheinlichkeit**: $P(A\\mid B) = \\frac{P(A\\cap B)}{P(B)}$\n",
        "- **Bayes-Regel**: $P(A\\mid B) = \\frac{P(B\\mid A)\\,P(A)}{P(B)}$\n",
        "- **Verteilungen**: Normal-, Binomial-, Poisson-Verteilung\n",
        "- **Erwartungswert und Varianz**: charakterisieren eine Verteilung"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from scipy import stats\n",
        "import random\n",
        "\n",
        "print(\"=== Beispiel 1: Grundlegende Wahrscheinlichkeiten ===\")\n",
        "\n",
        "print(\"Würfel (6 mögliche Ergebnisse):\")\n",
        "print(f\"P(1) = {1/6:.4f}\")\n",
        "print(f\"P(gerade Zahl) = P(2,4,6) = {3/6:.4f}\")\n",
        "\n",
        "print(\"\\nMünze werfen:\")\n",
        "print(f\"P(Kopf) = {1/2:.4f}\")\n",
        "print(f\"P(Zahl) = {1/2:.4f}\")\n",
        "\n",
        "print(\"\\nZwei unabhängige Münzwürfe:\")\n",
        "print(f\"P(Kopf AND Kopf) = {1/2 * 1/2:.4f}\")\n",
        "print(f\"P(mindestens ein Kopf) = {1 - (1/2 * 1/2):.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"\\n=== Beispiel 2: Bedingte Wahrscheinlichkeit und Bayes' Theorem ===\")\n",
        "\n",
        "# Beispiel: Krankheit und Test\n",
        "# P(Krankheit) = 0.01\n",
        "# P(Test positiv | Krankheit) = 0.99 (Sensitivität)\n",
        "# P(Test positiv | keine Krankheit) = 0.05 (falsch positiv)\n",
        "\n",
        "P_disease = 0.01\n",
        "P_positive_given_disease = 0.99\n",
        "P_positive_given_no_disease = 0.05\n",
        "\n",
        "P_no_disease = 1 - P_disease\n",
        "\n",
        "P_positive = (\n",
        "    P_positive_given_disease * P_disease\n",
        "    + P_positive_given_no_disease * P_no_disease\n",
        ")\n",
        "\n",
        "P_disease_given_positive = (P_positive_given_disease * P_disease) / P_positive\n",
        "\n",
        "print(f\"P(Krankheit) = {P_disease:.4f}\")\n",
        "print(f\"P(Test positiv | Krankheit) = {P_positive_given_disease:.4f}\")\n",
        "print(f\"P(Test positiv | keine Krankheit) = {P_positive_given_no_disease:.4f}\")\n",
        "print(f\"\\nP(Test positiv) = {P_positive:.4f}\")\n",
        "print(\"\\nBayes' Theorem:\")\n",
        "print(f\"P(Krankheit | Test positiv) = {P_disease_given_positive:.4f}\")\n",
        "print(f\"\\n→ Trotz positiven Test: Nur {P_disease_given_positive*100:.1f}% Wahrscheinlichkeit für Krankheit\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"\\n=== Beispiel 3: Diskrete Verteilungen ===\")\n",
        "\n",
        "n = 10\n",
        "p = 0.5\n",
        "\n",
        "print(\"Binomialverteilung (10 Münzwürfe):\")\n",
        "for k in range(0, n + 1, 2):\n",
        "    prob = stats.binom.pmf(k, n, p)\n",
        "    print(f\"P(X = {k}) = {prob:.4f}\")\n",
        "\n",
        "mean_binom = n * p\n",
        "var_binom = n * p * (1 - p)\n",
        "std_binom = np.sqrt(var_binom)\n",
        "\n",
        "print(f\"\\nErwartungswert E[X] = n*p = {mean_binom:.2f}\")\n",
        "print(f\"Varianz Var[X] = n*p*(1-p) = {var_binom:.2f}\")\n",
        "print(f\"Standardabweichung σ = {std_binom:.2f}\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 50)\n",
        "print(\"Poisson-Verteilung (λ = 3):\")\n",
        "lambda_param = 3\n",
        "for k in range(0, 8):\n",
        "    prob = stats.poisson.pmf(k, lambda_param)\n",
        "    print(f\"P(X = {k}) = {prob:.4f}\")\n",
        "\n",
        "mean_poisson = lambda_param\n",
        "var_poisson = lambda_param\n",
        "print(f\"\\nErwartungswert E[X] = λ = {mean_poisson}\")\n",
        "print(f\"Varianz Var[X] = λ = {var_poisson}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"\\n=== Beispiel 4: Normalverteilung (Gaußverteilung) ===\")\n",
        "\n",
        "mu = 100\n",
        "sigma = 15\n",
        "\n",
        "x = np.linspace(mu - 4 * sigma, mu + 4 * sigma, 1000)\n",
        "y = stats.norm.pdf(x, mu, sigma)\n",
        "\n",
        "P_less_110 = stats.norm.cdf(110, mu, sigma)\n",
        "P_between = stats.norm.cdf(115, mu, sigma) - stats.norm.cdf(85, mu, sigma)\n",
        "\n",
        "print(f\"Normalverteilung mit μ = {mu}, σ = {sigma}\")\n",
        "print(f\"\\nP(X ≤ 110) = {P_less_110:.4f}\")\n",
        "print(f\"P(85 ≤ X ≤ 115) = {P_between:.4f}\")\n",
        "\n",
        "z_score = (110 - mu) / sigma\n",
        "print(f\"\\nZ-Score für X = 110: z = {z_score:.4f}\")\n",
        "print(f\"P(Z ≤ {z_score:.4f}) = {stats.norm.cdf(z_score):.4f}\")\n",
        "\n",
        "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "ax = axes[0]\n",
        "ax.plot(x, y, linewidth=2, label='N(μ=100, σ=15)')\n",
        "x_fill = x[x <= 110]\n",
        "y_fill = stats.norm.pdf(x_fill, mu, sigma)\n",
        "ax.fill_between(x_fill, y_fill, alpha=0.3, label='P(X ≤ 110)')\n",
        "ax.axvline(mu, linestyle='--', label=f'μ = {mu}')\n",
        "ax.set_xlabel('x')\n",
        "ax.set_ylabel('Wahrscheinlichkeitsdichte')\n",
        "ax.set_title('Normalverteilung - PDF')\n",
        "ax.legend()\n",
        "ax.grid(True, alpha=0.3)\n",
        "\n",
        "y_cdf = stats.norm.cdf(x, mu, sigma)\n",
        "ax = axes[1]\n",
        "ax.plot(x, y_cdf, linewidth=2)\n",
        "ax.axhline(P_less_110, linestyle='--', alpha=0.5)\n",
        "ax.axvline(110, linestyle='--', alpha=0.5)\n",
        "ax.plot(110, P_less_110, marker='o', markersize=8)\n",
        "ax.set_xlabel('x')\n",
        "ax.set_ylabel('Kumulierte Wahrscheinlichkeit')\n",
        "ax.set_title('Normalverteilung - CDF')\n",
        "ax.grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"\\n=== Beispiel 5: Stichprobenziehen und Verteilungsvergleich ===\")\n",
        "\n",
        "np.random.seed(42)\n",
        "\n",
        "n_samples = 100000\n",
        "sample_size = 30\n",
        "\n",
        "sample_means = []\n",
        "for _ in range(n_samples):\n",
        "    samples = np.random.exponential(scale=2, size=sample_size)\n",
        "    sample_means.append(np.mean(samples))\n",
        "\n",
        "sample_means = np.array(sample_means)\n",
        "\n",
        "print(\"Exponentialverteilung (Skala=2) Stichproben ziehen:\")\n",
        "print(f\"Stichprobengröße: {sample_size}\")\n",
        "print(f\"Anzahl Stichproben: {n_samples}\")\n",
        "print(f\"\\nMittelwert der Stichprobenmittel: {np.mean(sample_means):.4f}\")\n",
        "print(f\"Standardabweichung der Stichprobenmittel: {np.std(sample_means):.4f}\")\n",
        "\n",
        "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
        "\n",
        "original = np.random.exponential(scale=2, size=5000)\n",
        "axes[0].hist(original, bins=50, density=True, alpha=0.7, label='Originalverteilung (Exponential)')\n",
        "axes[0].set_xlabel('Wert')\n",
        "axes[0].set_ylabel('Dichte')\n",
        "axes[0].set_title('Exponentialverteilung')\n",
        "axes[0].legend()\n",
        "\n",
        "axes[1].hist(sample_means, bins=50, density=True, alpha=0.7, label='Stichprobenmittel')\n",
        "x_normal = np.linspace(sample_means.min(), sample_means.max(), 200)\n",
        "y_normal = stats.norm.pdf(x_normal, np.mean(sample_means), np.std(sample_means))\n",
        "axes[1].plot(x_normal, y_normal, linewidth=2, label='Normalverteilung')\n",
        "axes[1].set_xlabel('Stichprobenmittel')\n",
        "axes[1].set_ylabel('Dichte')\n",
        "axes[1].set_title('Zentraler Grenzwertsatz')\n",
        "axes[1].legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"\\n→ Trotz Exponentialverteilung der Originalwerte sind die Stichprobenmittel näherungsweise normalverteilt!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"\\n=== Beispiel 6: Kovarianz und Korrelation ===\")\n",
        "\n",
        "np.random.seed(42)\n",
        "n = 1000\n",
        "\n",
        "X = np.random.normal(0, 1, n)\n",
        "noise = np.random.normal(0, 0.5, n)\n",
        "Y = 2 * X + noise\n",
        "\n",
        "mean_X = np.mean(X)\n",
        "mean_Y = np.mean(Y)\n",
        "std_X = np.std(X)\n",
        "std_Y = np.std(Y)\n",
        "\n",
        "cov = np.cov(X, Y)[0, 1]\n",
        "corr = np.corrcoef(X, Y)[0, 1]\n",
        "\n",
        "print(f\"Statistiken von X: μ = {mean_X:.4f}, σ = {std_X:.4f}\")\n",
        "print(f\"Statistiken von Y: μ = {mean_Y:.4f}, σ = {std_Y:.4f}\")\n",
        "print(f\"\\nKovarianz Cov(X,Y) = {cov:.4f}\")\n",
        "print(f\"Korrelation Corr(X,Y) = {corr:.4f}\")\n",
        "\n",
        "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
        "\n",
        "axes[0].scatter(X, Y, alpha=0.5, s=10)\n",
        "z = np.polyfit(X, Y, 1)\n",
        "p = np.poly1d(z)\n",
        "x_line = np.linspace(X.min(), X.max(), 100)\n",
        "axes[0].plot(x_line, p(x_line), linewidth=2, label='Linearer Fit')\n",
        "axes[0].set_xlabel('X')\n",
        "axes[0].set_ylabel('Y')\n",
        "axes[0].set_title(f'Streudiagramm (Korrelation: {corr:.3f})')\n",
        "axes[0].legend()\n",
        "axes[0].grid(True, alpha=0.3)\n",
        "\n",
        "cov_matrix = np.cov(X, Y)\n",
        "im = axes[1].imshow(cov_matrix)\n",
        "plt.colorbar(im, ax=axes[1])\n",
        "axes[1].set_title('Kovarianzmatrix')\n",
        "axes[1].set_xticks([0, 1])\n",
        "axes[1].set_xticklabels(['X', 'Y'])\n",
        "axes[1].set_yticks([0, 1])\n",
        "axes[1].set_yticklabels(['X', 'Y'])\n",
        "for i in range(2):\n",
        "    for j in range(2):\n",
        "        axes[1].text(j, i, f'{cov_matrix[i, j]:.2f}', ha='center', va='center')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"\\n=== Beispiel 7: Maximum Likelihood Estimation (MLE) ===\")\n",
        "\n",
        "np.random.seed(42)\n",
        "true_mu = 5\n",
        "true_sigma = 2\n",
        "data = np.random.normal(true_mu, true_sigma, 100)\n",
        "\n",
        "print(f\"Wahre Parameter: μ = {true_mu}, σ = {true_sigma}\")\n",
        "print(f\"\\nStichprobe hat {len(data)} Datenpunkte\")\n",
        "\n",
        "# MLE-Schätzer (für Normalverteilung, hier mit Populations-Std: ddof=0)\n",
        "estimated_mu = np.mean(data)\n",
        "estimated_sigma = np.std(data)\n",
        "\n",
        "print(\"\\nMLE Schätzungen:\")\n",
        "print(f\"μ̂ = {estimated_mu:.4f} (wahr: {true_mu})\")\n",
        "print(f\"σ̂ = {estimated_sigma:.4f} (wahr: {true_sigma})\")\n",
        "\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.hist(data, bins=30, density=True, alpha=0.7, label='Daten')\n",
        "\n",
        "x = np.linspace(data.min(), data.max(), 200)\n",
        "y_true = stats.norm.pdf(x, true_mu, true_sigma)\n",
        "plt.plot(x, y_true, linewidth=2, label=f'Wahre N({true_mu}, {true_sigma})')\n",
        "\n",
        "y_est = stats.norm.pdf(x, estimated_mu, estimated_sigma)\n",
        "plt.plot(x, y_est, linestyle='--', linewidth=2, label=f'Geschätzte N({estimated_mu:.2f}, {estimated_sigma:.2f})')\n",
        "\n",
        "plt.xlabel('Wert')\n",
        "plt.ylabel('Wahrscheinlichkeitsdichte')\n",
        "plt.title('Maximum Likelihood Estimation')\n",
        "plt.legend()\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Zusammenfassung\n",
        "\n",
        "In diesem Kapitel haben wir die drei fundamentalen mathematischen Konzepte behandelt:\n",
        "\n",
        "### 1. **Gradientenberechnung**\n",
        "- Gradient zeigt Richtung des steilsten Anstiegs\n",
        "- Essentiell für Optimierungsverfahren (Gradient Descent)\n",
        "- Numerische vs. analytische Berechnung\n",
        "\n",
        "### 2. **Matrizenrechnung**\n",
        "- Grundlegende Operationen (Addition, Multiplikation, Transponieren)\n",
        "- Determinante und Inverse\n",
        "- Eigenwerte und Eigenvektoren\n",
        "- Lösen linearer Gleichungssysteme\n",
        "\n",
        "### 3. **Wahrscheinlichkeitsrechnung**\n",
        "- Grundlegende Wahrscheinlichkeitskonzepte\n",
        "- Bedingte Wahrscheinlichkeit und Bayes' Theorem\n",
        "- Diskrete Verteilungen (Binomial, Poisson)\n",
        "- Normalverteilung und Zentraler Grenzwertsatz\n",
        "- Kovarianz, Korrelation und Maximum Likelihood Estimation\n",
        "\n",
        "Diese Konzepte bilden die mathematische Grundlage für Machine Learning und künstliche Intelligenz!"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
