{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Self-Attention – vollständiges Rechenbeispiel (wie auf der Folie)\n",
    "\n",
    "Wir rechnen eine **vereinfachte Self-Attention** (1 Head, 1 Layer) für die Tokenfolge:\n",
    "\n",
    "- Paris\n",
    "- ist\n",
    "- die\n",
    "- Hauptstadt\n",
    "- von (**Fokus-Token**)\n",
    "\n",
    "Wir verwenden **4-dimensionale Eingabevektoren** und einfache Gewichtsmatrizen:\n",
    "- $W_Q = I$\n",
    "- $W_K = W_V = 0.5\\,I$\n",
    "\n",
    "Dann berechnen wir:\n",
    "1. Eingabevektoren $x$\n",
    "2. Gewichtsmatrizen $W_Q, W_K, W_V$\n",
    "3. Query $q_{von}$\n",
    "4. Keys $k_j$\n",
    "5. Scores $\\frac{q\\cdot k}{\\sqrt{d}}$\n",
    "6. Softmax-Gewichte $\\alpha_j$\n",
    "7. Values $v_j$\n",
    "8. Output $\\sum_j \\alpha_j v_j$\n",
    "\n",
    "---\n",
    "\n",
    "Zusätzlich (wie gewünscht):\n",
    "- **Schritt-für-Schritt-Ausgabe** (jede Zwischenrechnung als Text)\n",
    "- **Mini-Visualisierung** der Softmax-Gewichte \\(\\alpha\\)\n"
   ],
   "id": "ae9e09b9fe50b040"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "np.set_printoptions(suppress=True)\n"
   ],
   "id": "e6e0065a9f75318"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Schritt 1: Eingabevektoren $x$\n",
    "\n",
    "Die Vektoren sind **frei gewählt** (didaktisch), wie in deiner Grafik."
   ],
   "id": "5fd91a9c55b3bfbd"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = [\"Paris\", \"ist\", \"die\", \"Hauptstadt\", \"von\"]\n",
    "\n",
    "X = {\n",
    "    \"Paris\":      np.array([2, 0, 1, 1], dtype=float),\n",
    "    \"ist\":        np.array([0, 2, 0, 1], dtype=float),\n",
    "    \"die\":        np.array([1, 1, 0, 0], dtype=float),\n",
    "    \"Hauptstadt\": np.array([0, 1, 3, 1], dtype=float),\n",
    "    \"von\":        np.array([1, 2, 1, 0], dtype=float),  # Fokus-Token\n",
    "}\n",
    "\n",
    "df_x = pd.DataFrame({t: X[t] for t in tokens}).T\n",
    "df_x.columns = [\"x1\", \"x2\", \"x3\", \"x4\"]\n",
    "df_x\n"
   ],
   "id": "85e8466dac44f384"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Schritt 2: Gewichtsmatrizen\n",
    "\n",
    "- $W_Q = I$\n",
    "- $W_K = W_V = 0.5\\,I$\n"
   ],
   "id": "1d49b007c6ecb1c1"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = 4\n",
    "Wq = np.eye(d)\n",
    "Wk = 0.5 * np.eye(d)\n",
    "Wv = 0.5 * np.eye(d)\n",
    "\n",
    "print(\"Wq =\\n\", Wq)\n",
    "print(\"\\nWk =\\n\", Wk)\n",
    "print(\"\\nWv =\\n\", Wv)\n"
   ],
   "id": "7c95270220621b07"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Schritt 3: Query \\(q_{von} = W_Q x_{von}\\)\n",
    "\n",
    "Da $W_Q = I$, gilt hier direkt $q_{von} = x_{von}$."
   ],
   "id": "7d6664c41e967ce4"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_von = Wq @ X[\"von\"]\n",
    "print(\"q_von =\", q_von)\n"
   ],
   "id": "a824d164ec84145f"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Schritt 4: Keys $k_j = W_K x_j$\n",
    "\n",
    "Wir berechnen die Keys für die vorherigen Tokens (Paris, ist, die, Hauptstadt)."
   ],
   "id": "abb5efadf6c17c73"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "context_tokens = [\"Paris\", \"ist\", \"die\", \"Hauptstadt\"]\n",
    "\n",
    "K = {t: (Wk @ X[t]) for t in context_tokens}\n",
    "df_k = pd.DataFrame({t: K[t] for t in context_tokens}).T\n",
    "df_k.columns = [\"k1\", \"k2\", \"k3\", \"k4\"]\n",
    "df_k\n"
   ],
   "id": "8ec5aa242137d061"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Schritt 5: Scores\n",
    "\n",
    "$$\n",
    "score_j = \\frac{q_{von} \\cdot k_j}{\\sqrt{d}}\\quad\\text{mit}\\quad d=4,\\ \\sqrt{d}=2\n",
    "$$\n"
   ],
   "id": "da43fd4d7d712c9c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sqrt_d = np.sqrt(d)\n",
    "\n",
    "dot = {t: float(q_von @ K[t]) for t in context_tokens}\n",
    "score = {t: dot[t] / sqrt_d for t in context_tokens}\n",
    "\n",
    "df_scores = pd.DataFrame({\n",
    "    \"Skalarprodukt (q·k)\": [dot[t] for t in context_tokens],\n",
    "    \"Score = (q·k)/sqrt(d)\": [score[t] for t in context_tokens],\n",
    "}, index=context_tokens)\n",
    "\n",
    "df_scores\n"
   ],
   "id": "573b2d9a4387432e"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Schritt 6: Softmax-Gewichte $\\alpha_j$\n",
    "\n",
    "$$\n",
    "\\alpha_j = \\frac{e^{score_j}}{\\sum_k e^{score_k}}\n",
    "$$\n",
    "\n",
    "Wir zeigen auch $e^{score}$ und die Summe."
   ],
   "id": "3bd541d1ef465905"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_vec = np.array([score[t] for t in context_tokens], dtype=float)\n",
    "e_score = np.exp(score_vec)\n",
    "sum_e = float(np.sum(e_score))\n",
    "alpha = e_score / sum_e\n",
    "\n",
    "df_softmax = pd.DataFrame({\n",
    "    \"e^Score\": e_score,\n",
    "    \"Gewicht α\": alpha,\n",
    "}, index=context_tokens)\n",
    "\n",
    "df_softmax\n"
   ],
   "id": "307220bc71bb65c8"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Schritt 7: Values $v_j = W_V x_j$\n",
    "\n",
    "Da $W_V = 0.5I$, sind die Values in diesem Beispiel **identisch** zu den Keys."
   ],
   "id": "620c5c5074965085"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "V = {t: (Wv @ X[t]) for t in context_tokens}\n",
    "df_v = pd.DataFrame({t: V[t] for t in context_tokens}).T\n",
    "df_v.columns = [\"v1\", \"v2\", \"v3\", \"v4\"]\n",
    "df_v\n"
   ],
   "id": "d97d15bac1f2e7de"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Schritt 8: Finaler Output-Vektor für „von“\n",
    "\n",
    "$$\n",
    "output = \\sum_j \\alpha_j \\cdot v_j\n",
    "$$\n"
   ],
   "id": "5feaee1fbf47ef70"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = np.zeros(d)\n",
    "for i, t in enumerate(context_tokens):\n",
    "    output += alpha[i] * V[t]\n",
    "\n",
    "output\n"
   ],
   "id": "8ba937269b463c49"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ergebnis & Check gegen die Folie\n",
    "\n",
    "Folie (gerundet): **[0.304, 0.529, 0.603, 0.339]**"
   ],
   "id": "fa0569b95bd20295"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expected = np.array([0.304, 0.529, 0.603, 0.339])\n",
    "\n",
    "print(\"Output (raw):\", output)\n",
    "print(\"Output (rounded 3):\", np.round(output, 3))\n",
    "print(\"Expected:\", expected)\n",
    "print(\"\\nAbweichung:\", np.round(output - expected, 6))\n"
   ],
   "id": "806a628800855f80"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zusatz A: Schritt-für-Schritt-Ausgabe (für Live-Demo)\n",
    "\n",
    "Diese Zelle druckt **jede Zwischenrechnung** genau in der Reihenfolge der Folie."
   ],
   "id": "2cafc42c483d9932"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fmt_vec(v, nd=3):\n",
    "    return \"[\" + \", \".join(f\"{x:.{nd}f}\" for x in v) + \"]\"\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"SCHRITT 1: Eingabevektoren x\")\n",
    "for t in tokens:\n",
    "    print(f\"{t:10s}: {fmt_vec(X[t], 0)}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"SCHRITT 2: Gewichtsmatrizen\")\n",
    "print(\"Wq = I\")\n",
    "print(Wq)\n",
    "print(\"\\nWk = 0.5 I\")\n",
    "print(Wk)\n",
    "print(\"\\nWv = 0.5 I\")\n",
    "print(Wv)\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"SCHRITT 3: Query q_von = Wq * x_von\")\n",
    "print(\"x_von   =\", fmt_vec(X[\"von\"], 0))\n",
    "print(\"q_von   =\", fmt_vec(q_von, 0))\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"SCHRITT 4: Keys k_j = Wk * x_j\")\n",
    "for t in context_tokens:\n",
    "    print(f\"k_{t:10s}= {fmt_vec(K[t], 3)}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"SCHRITT 5: Scores score_j = (q·k)/sqrt(d), d=4 -> sqrt(d)=2\")\n",
    "print(\"q_von =\", fmt_vec(q_von, 3))\n",
    "print(\"sqrt(d)=\", sqrt_d)\n",
    "for t in context_tokens:\n",
    "    print(f\"{t:10s}: q·k = {dot[t]:.3f}  -> score = {score[t]:.3f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"SCHRITT 6: Softmax\")\n",
    "for i, t in enumerate(context_tokens):\n",
    "    print(f\"{t:10s}: e^score = {e_score[i]:.3f}\")\n",
    "print(\"Summe e^score =\", f\"{sum_e:.3f}\")\n",
    "for i, t in enumerate(context_tokens):\n",
    "    print(f\"{t:10s}: alpha = {alpha[i]:.3f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"SCHRITT 7: Values v_j = Wv * x_j\")\n",
    "for t in context_tokens:\n",
    "    print(f\"v_{t:10s}= {fmt_vec(V[t], 3)}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"SCHRITT 8: Output = Sum(alpha_j * v_j)\")\n",
    "tmp = np.zeros(d)\n",
    "for i, t in enumerate(context_tokens):\n",
    "    contrib = alpha[i] * V[t]\n",
    "    tmp += contrib\n",
    "    print(f\"+ {alpha[i]:.3f} * v_{t:10s} = {fmt_vec(contrib, 3)}\")\n",
    "print(\"-------------------------------------------\")\n",
    "print(\"Output =\", fmt_vec(tmp, 3))\n",
    "\n",
    "print(\"\\nVergleich Folie:\")\n",
    "print(\"Output (gerundet) =\", fmt_vec(np.round(output, 3), 3))\n",
    "print(\"Folie             =\", fmt_vec(expected, 3))\n",
    "print(\"=\"*70)\n"
   ],
   "id": "3a7e792101660cf8"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zusatz B: Mini-Visualisierung der Attention-Gewichte\n",
    "\n",
    "Wir plotten ein Balkendiagramm für \\(\\alpha\\) (wie die Balken in deiner Folie)."
   ],
   "id": "414b2c43f24dbda5"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sortiert nach Gewicht (wie typische Darstellung)\n",
    "order = np.argsort(alpha)[::-1]\n",
    "tok_sorted = [context_tokens[i] for i in order]\n",
    "alpha_sorted = alpha[order]\n",
    "score_sorted = score_vec[order]\n",
    "\n",
    "plt.figure(figsize=(7, 3.5))\n",
    "plt.bar(tok_sorted, alpha_sorted)\n",
    "plt.title(\"Attention-Gewichte α für Fokus-Token 'von'\")\n",
    "plt.ylabel(\"α\")\n",
    "plt.ylim(0, max(alpha_sorted) * 1.2)\n",
    "plt.grid(axis=\"y\", linestyle=\"--\", linewidth=0.5)\n",
    "\n",
    "# Werte über die Balken schreiben\n",
    "for i, v in enumerate(alpha_sorted):\n",
    "    plt.text(i, v + 0.01, f\"{v:.3f}\", ha=\"center\", va=\"bottom\")\n",
    "\n",
    "plt.show()\n"
   ],
   "id": "d793802da3ff3a12"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kompakte Tabelle (Token | Gewicht | Score)\n",
    "\n",
    "Wie in deiner zweiten Folie: sortiert nach Gewicht."
   ],
   "id": "d8d6bdea3868973c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_summary = pd.DataFrame({\n",
    "    \"Gewicht α\": alpha,\n",
    "    \"Score\": score_vec,\n",
    "    \"e^Score\": e_score,\n",
    "}, index=context_tokens)\n",
    "\n",
    "df_summary.sort_values(\"Gewicht α\", ascending=False)\n"
   ],
   "id": "110842a4158080f7"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Einordnung (wie im unteren Kasten deiner Folie)\n",
    "\n",
    "In großen Modellen wie GPT oder BERT passiert dieselbe Rechnung – nur mit:\n",
    "- **größeren Vektoren** (z. B. 768 oder mehr)\n",
    "- **mehreren Attention-Heads gleichzeitig**\n",
    "- **vielen Layern**, Residual-Verbindungen und LayerNorm\n"
   ],
   "id": "d0385e2044ec119b"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
